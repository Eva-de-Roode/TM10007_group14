{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "7d2a6d8b-4e85-46a7-f99e-cd70d0749723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ktml (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b_-bnn1_nBp"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "29ed0236-10b5-48f4-fad9-d8a9a4213aef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 186\n",
            "The number of columns: 494\n"
          ]
        }
      ],
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "import pandas as pd\n",
        "from worcliver.load_data import load_data\n",
        "\n",
        "\n",
        "data = load_data()\n",
        "data_df = pd.DataFrame(data)\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting the label per patient\n",
        "\n",
        "This label (benign/malignant) is the ground truth per patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ONVSyb_nBr",
        "outputId": "97d0a174-32d3-4270-81f2-00982ea8ec4f"
      },
      "outputs": [],
      "source": [
        "label = data_df[['label']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dividing our data into test-, training- and validation-set\n",
        "\n",
        "The dataset should be randomly divided into :\n",
        "* training datasets = 70 % of samples\n",
        "* test datasets = 20 % of samples\n",
        "* validation datasets = 10 % of samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding the missing data\n",
        "\n",
        "Checking whether the missing data is stored as NaN or 0, finding the columns in which missing data is found as well as the empty features.\n",
        "\n",
        "\n",
        "*--> dit moet alleen over de trainingsset gedaan worden toch? dat weghalen van de missing data enzo? voor nu is dit dus gedaan over de hele dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of features in which there is missing data: 22\n",
            "The number of missing data is: 3039\n",
            "The total number of features containing zeros (so no data) is: 0\n",
            "The number of features in which there is missing data (excluding empty features): 22\n",
            "The number of missing data is (excluding empty features): 3039\n"
          ]
        }
      ],
      "source": [
        "#checking whether missing data is stored as NaN\n",
        "nan_check = data_df.isna()\n",
        "\n",
        "#conclusion: missing data is not stored as NaN\n",
        "\n",
        "#checking whether missing data is stored as 0\n",
        "zero_counts = (data_df == 0).sum()\n",
        "\n",
        "#conclusion: missing data is stored as 0\n",
        "\n",
        "zero_counts_columns = zero_counts[zero_counts > 0]\n",
        "print(f'The number of features in which there is missing data: {zero_counts_columns.count()}')\n",
        "print(f'The number of missing data is: {sum(zero_counts_columns)}')\n",
        "\n",
        "empty_features = zero_counts_columns[zero_counts_columns == len(data_df.index)]\n",
        "print(f'The total number of features containing zeros (so no data) is: {empty_features.count()}')\n",
        "print(f'The number of features in which there is missing data (excluding empty features): {zero_counts_columns.count()-empty_features.count()}')\n",
        "print(f'The number of missing data is (excluding empty features): {sum(zero_counts_columns)-empty_features.count()*len(data.index)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling the missing data\n",
        "\n",
        "The missing data was handled as follows:\n",
        "1. Deleting the empty features from the data\n",
        "2. ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of columns after deleting the empty features: 487\n"
          ]
        }
      ],
      "source": [
        "#step 1: deleting the empty features\n",
        "data_cleaned = data_df.drop(columns=empty_features.index, inplace=True)\n",
        "print(f'The number of columns after deleting the empty features: {len(data_df.columns)}')\n",
        "\n",
        "#step 2: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
