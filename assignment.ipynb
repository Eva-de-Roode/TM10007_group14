{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "7d2a6d8b-4e85-46a7-f99e-cd70d0749723"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#general packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b_-bnn1_nBp"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "29ed0236-10b5-48f4-fad9-d8a9a4213aef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 186\n",
            "The number of columns: 494\n"
          ]
        }
      ],
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "import pandas as pd\n",
        "from worcliver.load_data import load_data\n",
        "\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dividing our data into test-, training- and validation-set\n",
        "\n",
        "The dataset should be randomly divided into :\n",
        "* training datasets = 70 % of samples\n",
        "* test datasets = 20 % of samples\n",
        "* validation datasets = 10 % of samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: 130 samples, Test: 37 samples, Validation: 19 samples.\n",
            "So total number of samples: 186\n"
          ]
        }
      ],
      "source": [
        "amount_in_training = round(len(data.index)*0.7)\n",
        "amount_in_test = round(len(data.index)*0.2)\n",
        "amount_in_validation = len(data.index) - amount_in_training - amount_in_test\n",
        "\n",
        "#split the data into training data and test+validation data\n",
        "training_data, test_validation_data = model_selection.train_test_split(data, test_size=(amount_in_test + amount_in_validation) / len(data), random_state=42)\n",
        "\n",
        "#split the test+validation data into seperate sets for test and validation\n",
        "test_data, validation_data = model_selection.train_test_split(test_validation_data, test_size=amount_in_validation / (amount_in_test + amount_in_validation), random_state=42)\n",
        "\n",
        "#checking the lengths\n",
        "print(f'Training: {len(training_data)} samples, Test: {len(test_data)} samples, Validation: {len(validation_data)} samples.')\n",
        "print(f'So total number of samples: {len(training_data)+len(test_data)+len(validation_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting the label per patient\n",
        "\n",
        "This label (benign/malignant) is the ground truth per patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ONVSyb_nBr",
        "outputId": "97d0a174-32d3-4270-81f2-00982ea8ec4f"
      },
      "outputs": [],
      "source": [
        "label_training = training_data[['label']]\n",
        "training_data.drop(columns=['label'], inplace=True)\n",
        "\n",
        "label_training_binary = label_training.copy()\n",
        "label_training_binary['label'] = label_training_binary['label'].map({'malignant': 1, 'benign': 0})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding the missing data\n",
        "\n",
        "Checking whether the missing data is stored as NaN or 0, finding the columns in which missing data is found as well as the empty features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of features in which there is missing data: 29\n",
            "The number of missing data is: 3046\n"
          ]
        }
      ],
      "source": [
        "#making a dataframe\n",
        "data_training = pd.DataFrame(training_data)\n",
        "\n",
        "#checking whether missing data is stored as NaN\n",
        "nan_check = data_training.isna()\n",
        "\n",
        "#conclusion: missing data is not stored as NaN\n",
        "\n",
        "#checking whether missing data is stored as 0\n",
        "zero_counts = (data_training == 0).sum()\n",
        "\n",
        "#conclusion: missing data is stored as 0\n",
        "\n",
        "zero_counts_columns = zero_counts[zero_counts > 0]\n",
        "print(f'The number of features in which there is missing data: {zero_counts_columns.count()}')\n",
        "print(f'The number of missing data is: {sum(zero_counts_columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling the missing data\n",
        "\n",
        "The missing data was handled as follows:\n",
        "1. Deleting the empty features from the data\n",
        "2. Replacing the missing data with the median value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The amount of data missing in PREDICT_original_tf_LBP_quartile_range_R8_P24 is 31\n",
            "The amount of data missing in PREDICT_original_phasef_monogenic_peak_WL3_N5 is 3\n",
            "The amount of data missing in PREDICT_original_phasef_monogenic_peak_position_WL3_N5 is 3\n",
            "The amount of data missing in PREDICT_original_phasef_phasecong_quartile_range_WL3_N5 is 22\n",
            "The amount of data missing in PREDICT_original_phasef_phasesym_quartile_range_WL3_N5 is 47\n",
            "Empty features: 24, Features with missing data: 5.\n"
          ]
        }
      ],
      "source": [
        "#step 1: deleting the empty features from the data\n",
        "#a feature is empty when it contains values for <30% of the samples\n",
        "#   empty_features = the features that are considered empty\n",
        "#   missing_data_features = the features that contain missing data\n",
        "empty_features = []\n",
        "missing_data_features = []\n",
        "\n",
        "for feature, missing_data in zero_counts_columns.items():  \n",
        "    if missing_data > 0.7*len(data_training.index):\n",
        "        empty_features.append(feature)\n",
        "    else:\n",
        "        missing_data_features.append(feature)\n",
        "        print(f'The amount of data missing in {feature} is {missing_data}')\n",
        "\n",
        "data_training_clean = data_training.drop(columns=empty_features)\n",
        "\n",
        "print(f'Empty features: {len(empty_features)}, Features with missing data: {len(missing_data_features)}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To check: the number of features in which there is missing data is now: 0\n"
          ]
        }
      ],
      "source": [
        "#step 2: replacing the missing data with the median\n",
        "for feature in missing_data_features:\n",
        "    data_training_clean[feature].replace(0, np.nan, inplace=True)\n",
        "    \n",
        "    # Vervang de NaN waarden door de mediaan\n",
        "    median_value = data_training_clean[feature].median()\n",
        "    data_training_clean[feature].fillna(median_value, inplace=True)\n",
        "\n",
        "check_zero_counts = (data_training_clean == 0).sum()\n",
        "check_zero_counts_columns = check_zero_counts[check_zero_counts > 0]\n",
        "print(f'To check: the number of features in which there is missing data is now: {check_zero_counts_columns.count()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pre-processing: standardization/normalization\n",
        "\n",
        "First is tested whether the data is normally distributed or not with the Shapiro-Wilk Test. \n",
        "* p-value > 0.05: the data is likely normally distributed\n",
        "* p-value < 0.05: the data is likely not normally distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of features that do not have variation in their values is: 10\n",
            "The number of normally distributed features is: 53\n"
          ]
        }
      ],
      "source": [
        "shapiro_results = {}\n",
        "no_variation = 0\n",
        "features_no_variation = []\n",
        "\n",
        "for feature in data_training_clean.columns:\n",
        "    if data_training_clean[feature].max() == data_training_clean[feature].min():\n",
        "        shapiro_results[feature] = None  #skipping the feature when there is no variation                   WILLEN WE DEZE FEATURE DAN OOK WISSEN?\n",
        "        no_variation += 1\n",
        "        features_no_variation.append(feature)\n",
        "    else:\n",
        "        #Shapiro-Wilk test to check for normality\n",
        "        stat, p_value = stats.shapiro(data_training_clean[feature])\n",
        "\n",
        "        #if normally distributed, store 1, else store 0\n",
        "        if p_value > 0.05:\n",
        "            result = 1\n",
        "        else:\n",
        "            result = 0\n",
        "\n",
        "        shapiro_results[feature] = result\n",
        "\n",
        "#the number of normally distributed features\n",
        "print(f'The number of features that do not have variation in their values is: {no_variation}')\n",
        "print(f'The number of normally distributed features is: {sum(1 for result in shapiro_results.values() if result == 1)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#code from workgroup; sklearn package has a function that standardizes the data, so this is applied here:\n",
        "scaler = preprocessing.StandardScaler()\n",
        "data_training_standardized = scaler.fit_transform(data_training_clean)\n",
        "data_training_standardized_df = pd.DataFrame(data_training_standardized, columns=data_training_clean.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m seaborn\u001b[38;5;241m.\u001b[39mheatmap(corr_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Correlation Heatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:445\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    444\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:177\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    175\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:221\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    340\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py:2342\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2342\u001b[0m         bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2343\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2344\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pad_inches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2345\u001b[0m             pad_inches \u001b[38;5;241m=\u001b[39m rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msavefig.pad_inches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:1757\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1754\u001b[0m         \u001b[38;5;66;03m# subfigures do not have bbox_inches, but do have a bbox\u001b[39;00m\n\u001b[0;32m   1755\u001b[0m         bb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox]\n\u001b[1;32m-> 1757\u001b[0m _bbox \u001b[38;5;241m=\u001b[39m \u001b[43mBbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfigure:\n\u001b[0;32m   1760\u001b[0m     \u001b[38;5;66;03m# transform from pixels to inches...\u001b[39;00m\n\u001b[0;32m   1761\u001b[0m     _bbox \u001b[38;5;241m=\u001b[39m TransformedBbox(_bbox, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdpi_scale_trans\u001b[38;5;241m.\u001b[39minverted())\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py:657\u001b[0m, in \u001b[0;36mBboxBase.union\u001b[1;34m(bboxes)\u001b[0m\n\u001b[0;32m    655\u001b[0m x1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax([bbox\u001b[38;5;241m.\u001b[39mxmax \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes])\n\u001b[0;32m    656\u001b[0m y0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin([bbox\u001b[38;5;241m.\u001b[39mymin \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes])\n\u001b[1;32m--> 657\u001b[0m y1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax([bbox\u001b[38;5;241m.\u001b[39mymax \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes])\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Bbox([[x0, y0], [x1, y1]])\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py:657\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    655\u001b[0m x1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax([bbox\u001b[38;5;241m.\u001b[39mxmax \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes])\n\u001b[0;32m    656\u001b[0m y0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin([bbox\u001b[38;5;241m.\u001b[39mymin \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes])\n\u001b[1;32m--> 657\u001b[0m y1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax([\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mymax\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes])\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Bbox([[x0, y0], [x1, y1]])\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py:331\u001b[0m, in \u001b[0;36mBboxBase.ymax\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mymax\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124;03m\"\"\"The top edge of the bounding box.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\evade\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2793\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[0;32m   2678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2679\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2680\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2682\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2791\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2792\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2794\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "corr_matrix = data_training_standardized_df.corr()\n",
        "plt.figure(figsize=(20, 15))\n",
        "seaborn.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
