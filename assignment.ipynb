{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "7d2a6d8b-4e85-46a7-f99e-cd70d0749723"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "#general packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "from scipy import stats\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "29ed0236-10b5-48f4-fad9-d8a9a4213aef"
      },
      "outputs": [],
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "import pandas as pd\n",
        "from worcliver.load_data import load_data\n",
        "\n",
        "data = load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dividing our data into test-, training- and validation-set\n",
        "\n",
        "The dataset should be randomly divided into :\n",
        "* training datasets = 70 % of samples\n",
        "* test datasets = 20 % of samples\n",
        "* validation datasets = 10 % of samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training + validation: 149 samples, Test: 37 samples.\n",
            "So total number of samples: 186\n"
          ]
        }
      ],
      "source": [
        "amount_in_training = round(len(data.index)*0.7)\n",
        "amount_in_test = round(len(data.index)*0.2)\n",
        "amount_in_validation = len(data.index) - amount_in_training - amount_in_test\n",
        "\n",
        "#split the data into training+validation data and test data\n",
        "training_data, test_data = model_selection.train_test_split(data, test_size=(amount_in_test) / len(data), random_state=42)\n",
        "#random_state is set to a fixed value (in this case 42, which is an onofficial standard in machine learning), which ensures \n",
        "#that the same random division is made every time this code is ran.\n",
        "# --> to ensure that this is reproducible\n",
        "\n",
        "###\n",
        "\n",
        "#wat ik begreep uit college is dat validation en training samen blijven totdat je echt gaat trainen? dus inspectie is over deze 2 samen?\n",
        "\n",
        "###\n",
        "\n",
        "#checking the lengths\n",
        "print(f'Training + validation: {len(training_data)} samples, Test: {len(test_data)} samples.')\n",
        "print(f'So total number of samples: {len(training_data)+len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 149\n",
            "The number of columns: 494\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 149 entries, Liver-030_0 to Liver-103_0\n",
            "Columns: 494 entries, label to PREDICT_original_phasef_phasesym_entropy_WL3_N5\n",
            "dtypes: float64(468), int64(25), object(1)\n",
            "memory usage: 576.2+ KB\n",
            "None\n",
            "categorical columns: 1\n",
            "numerical columns: 493\n",
            "samples with no variation: 0\n",
            "columns with no variation: 19\n",
            "Class Distribution: malignant label    76\n",
            "dtype: int64 and benign label    73\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(f'The number of samples: {len(training_data.index)}')\n",
        "print(f'The number of columns: {len(training_data.columns)}')\n",
        "\n",
        "training_data_df = pd.DataFrame(training_data)\n",
        "#print(data_df.head())\n",
        "print(training_data_df.info())\n",
        "#print(data_df.describe())\n",
        "cat_cols = training_data_df.select_dtypes(include=[\"object\"]).columns\n",
        "num_cols = training_data_df.select_dtypes(include=[\"number\"]).columns\n",
        "print(f\"categorical columns: {len(cat_cols)}\")\n",
        "print(f'numerical columns: {len(num_cols)}')\n",
        "\n",
        "no_variation_samples = 0\n",
        "for sample in training_data.index:\n",
        "    data_sample = training_data.drop(columns=['label'])\n",
        "    if data_sample.loc[sample].max() == data_sample.loc[sample].min():\n",
        "        no_variation_samples += 1\n",
        "no_variation_col = 0\n",
        "for feature in training_data.columns:\n",
        "    if training_data[feature].max() == training_data[feature].min():\n",
        "        no_variation_col += 1\n",
        "print(f'samples with no variation: {no_variation_samples}')\n",
        "print(f'columns with no variation: {no_variation_col}')\n",
        "\n",
        "label = training_data[['label']]\n",
        "malignant_count = (label == \"malignant\").sum()\n",
        "benign_count = (label == \"benign\").sum()\n",
        "\n",
        "print(f'Class Distribution: malignant {malignant_count} and benign {benign_count}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting the label per patient\n",
        "\n",
        "This label (benign/malignant) is the ground truth per patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ONVSyb_nBr",
        "outputId": "97d0a174-32d3-4270-81f2-00982ea8ec4f"
      },
      "outputs": [],
      "source": [
        "label_training = training_data[['label']]\n",
        "training_data.drop(columns=['label'], inplace=True)\n",
        "\n",
        "label_training_binary = label_training.copy()\n",
        "label_training_binary['label'] = label_training_binary['label'].map({'malignant': 1, 'benign': 0})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding the missing data\n",
        "\n",
        "Checking whether the missing data is stored as NaN or 0, finding the columns in which missing data is found as well as the empty features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of features in which there is missing data: 29\n",
            "The number of missing data is: 3488\n"
          ]
        }
      ],
      "source": [
        "#making a dataframe\n",
        "data_training = pd.DataFrame(training_data)\n",
        "\n",
        "#checking whether missing data is stored as NaN\n",
        "nan_check = data_training.isna()\n",
        "\n",
        "#conclusion: missing data is not stored as NaN\n",
        "\n",
        "#checking whether missing data is stored as 0\n",
        "zero_counts = (data_training == 0).sum()\n",
        "\n",
        "#conclusion: missing data is stored as 0; however is this true? values in Radiomics can also be calculated as being 0, so how do you know if 0 is the\n",
        "#intended value, or a missing value? you can't, so do not consider the zeros as missing data.\n",
        "\n",
        "zero_counts_columns = zero_counts[zero_counts > 0]\n",
        "print(f'The number of features in which there is missing data: {zero_counts_columns.count()}')\n",
        "print(f'The number of missing data is: {sum(zero_counts_columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling the missing data\n",
        "\n",
        "The missing data was handled as follows:\n",
        "1. Deleting the empty features from the data\n",
        "2. Replacing the missing data with the median value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty features: 0, Features with missing data: 0.\n"
          ]
        }
      ],
      "source": [
        "#step 1: deleting the empty features from the data\n",
        "#a feature is empty when it contains values for <30% of the samples\n",
        "#   empty_features = the features that are considered empty\n",
        "#   missing_data_features = the features that contain missing data\n",
        "empty_features = []\n",
        "missing_data_features = []\n",
        "\n",
        "# for feature, missing_data in zero_counts_columns.items():  \n",
        "#     if missing_data > 0.7*len(data_training.index):\n",
        "#         empty_features.append(feature)\n",
        "#     else:\n",
        "#         missing_data_features.append(feature)\n",
        "#         print(f'The amount of data missing in {feature} is {missing_data}')\n",
        "\n",
        "data_training_clean = data_training.drop(columns=empty_features)\n",
        "\n",
        "print(f'Empty features: {len(empty_features)}, Features with missing data: {len(missing_data_features)}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To check: the number of features in which there is missing data is now: 29\n"
          ]
        }
      ],
      "source": [
        "#step 2: replacing the missing data with the median\n",
        "# for feature in missing_data_features:\n",
        "#     data_training_clean[feature].replace(0, np.nan, inplace=True)\n",
        "    \n",
        "#     # Vervang de NaN waarden door de mediaan\n",
        "#     median_value = data_training_clean[feature].median()\n",
        "#     data_training_clean[feature].fillna(median_value, inplace=True)\n",
        "check_zero_counts = (data_training_clean == 0).sum()\n",
        "check_zero_counts_columns = check_zero_counts[check_zero_counts > 0]\n",
        "print(f'To check: the number of features in which there is missing data is now: {check_zero_counts_columns.count()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pre-processing: standardization/normalization\n",
        "\n",
        "First is tested whether the data is normally distributed or not with the Shapiro-Wilk Test. \n",
        "* p-value > 0.05: the data is likely normally distributed\n",
        "* p-value < 0.05: the data is likely not normally distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of features that do not have variation in their values is: 19\n",
            "The number of normally distributed features is: 48\n",
            "The number of not normally distributed features is: 426\n"
          ]
        }
      ],
      "source": [
        "shapiro_results = {}\n",
        "no_variation = 0\n",
        "features_no_variation = []\n",
        "\n",
        "for feature in data_training_clean.columns:\n",
        "    if data_training_clean[feature].max() == data_training_clean[feature].min():\n",
        "        shapiro_results[feature] = None  #skipping the feature when there is no variation\n",
        "        no_variation += 1\n",
        "        features_no_variation.append(feature)\n",
        "    else:\n",
        "        #Shapiro-Wilk test to check for normality\n",
        "        stat, p_value = stats.shapiro(data_training_clean[feature])\n",
        "\n",
        "        #if normally distributed, store 1, else store 0\n",
        "        if p_value > 0.05:\n",
        "            result = 1\n",
        "        else:\n",
        "            result = 0\n",
        "\n",
        "        shapiro_results[feature] = result\n",
        "\n",
        "#the number of normally distributed features\n",
        "print(f'The number of features that do not have variation in their values is: {no_variation}')\n",
        "print(f'The number of normally distributed features is: {sum(1 for result in shapiro_results.values() if result == 1)}')\n",
        "print(f'The number of not normally distributed features is: {sum(1 for result in shapiro_results.values() if result == 0)}')\n",
        "\n",
        "#deleting the features in which there was no variation\n",
        "data_training_clean = data_training_clean.drop(columns=features_no_variation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "#code from workgroup; sklearn package has a function that standardizes the data, so this is applied here:\n",
        "scaler = preprocessing.StandardScaler()\n",
        "data_training_standardized = scaler.fit_transform(data_training_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " size of data training is: (149, 474)\n"
          ]
        }
      ],
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "data_training_normalized = min_max_scaler.fit_transform(data_training_standardized)\n",
        "data_training_normalized_df = pd.DataFrame(data_training_normalized, columns=data_training_clean.columns)\n",
        "print (f' size of data training is: {data_training_standardized.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = data_training_normalized_df.corr()\n",
        "\n",
        "plt.figure(figsize=(50, 50))\n",
        "seaborn.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 3876 feature pairs with a correlation above 0.9\n"
          ]
        }
      ],
      "source": [
        "threshold = 0.9  \n",
        "high_corr_pairs = np.where(np.abs(corr_matrix) > threshold)\n",
        "high_corr_features = [(corr_matrix.index[x], corr_matrix.columns[y], corr_matrix.iloc[x, y]) \n",
        "                      for x, y in zip(*high_corr_pairs) if x != y]\n",
        "print(f'There are {len(high_corr_features)} feature pairs with a correlation above {threshold}')\n",
        "\n",
        "# willen we nog iets met hoge coherenties wissen??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lasso feature selection "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.714e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.499e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.271e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.960e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.408e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.665e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.285e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.986e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e-02, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.324e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.484e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e-02, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.954e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.398e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.209e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e-02, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.683e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.405e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.687e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.882e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.722e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.684e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.524e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.124e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e-02, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.325e-03, tolerance: 3.349e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.533e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e-02, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e-02, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e-02, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.044e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.245e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.514e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e-02, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e-02, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.476e-03, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.526e-03, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.481e-03, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.662e-03, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e-03, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.094e-03, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e-02, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.513e-03, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.788e-03, tolerance: 3.350e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.685e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.541e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.489e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.766e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.713e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.212e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.950e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.914e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.089e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.650e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.657e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.911e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.037e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.700e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.348e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.032e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.561e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.788e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e-02, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.757e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.708e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.550e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e-02, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e-02, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e-02, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e-02, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.834e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e-02, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.755e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.712e-03, tolerance: 3.338e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.157e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e-02, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.347e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.165e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.032e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.820e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.341e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.272e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.321e-03, tolerance: 3.347e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.862e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.795e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.837e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.143e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.284e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.711e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.346e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.647e-03, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e-02, tolerance: 3.343e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.048e-03, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.876e-03, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.717e-03, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.837e-03, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.033e-03, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e-02, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.171e-02, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.547e-02, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.527e-03, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e-02, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e-02, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e-02, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.640e-03, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal Alpha: 0.006579332246575682\n",
            "Number of selected features: 34\n",
            "Final Selected Features: ['PREDICT_original_sf_prax_avg_2.5D', 'PREDICT_original_sf_area_min_2.5D', 'PREDICT_original_logf_kurtosis_sigma1', 'PREDICT_original_logf_peak_sigma1', 'PREDICT_original_logf_quartile_range_sigma1', 'PREDICT_original_logf_min_sigma5', 'PREDICT_original_logf_median_sigma10', 'PREDICT_original_logf_peak_position_sigma10', 'PREDICT_original_logf_quartile_range_sigma10', 'PREDICT_original_tf_LBP_std_R3_P12', 'PREDICT_original_tf_LBP_quartile_range_R8_P24', 'PREDICT_original_tf_GLCMMS_contrastd3.0A0.79std', 'PREDICT_original_tf_GLCMMS_homogeneityd3.0A2.36mean', 'PREDICT_original_tf_GLCMMS_ASMd3.0A1.57std', 'PREDICT_original_tf_GLCMMS_correlationd3.0A1.57std', 'PREDICT_original_tf_GLCMMS_correlationd3.0A2.36mean', 'PREDICT_original_tf_Gabor_peak_F0.05_A2.36', 'PREDICT_original_tf_Gabor_quartile_range_F0.05_A2.36', 'PREDICT_original_tf_Gabor_skewness_F0.2_A0.0', 'PREDICT_original_tf_Gabor_skewness_F0.2_A0.79', 'PREDICT_original_tf_Gabor_mean_F0.2_A1.57', 'PREDICT_original_tf_Gabor_skewness_F0.2_A1.57', 'PREDICT_original_tf_Gabor_min_F0.2_A2.36', 'PREDICT_original_tf_Gabor_skewness_F0.5_A0.0', 'PREDICT_original_tf_Gabor_kurtosis_F0.5_A0.0', 'PREDICT_original_tf_Gabor_kurtosis_F0.5_A1.57', 'PREDICT_original_tf_Gabor_quartile_range_F0.5_A2.36', 'PREDICT_original_vf_Frangi_full_entropy_SR(1.0, 10.0)_SS2.0', 'PREDICT_original_vf_Frangi_edge_entropy_SR(1.0, 10.0)_SS2.0', 'PREDICT_original_vf_Frangi_inner_entropy_SR(1.0, 10.0)_SS2.0', 'PREDICT_original_phasef_monogenic_peak_WL3_N5', 'PREDICT_original_phasef_monogenic_peak_position_WL3_N5', 'PREDICT_original_phasef_phasecong_entropy_WL3_N5', 'PREDICT_original_phasef_phasesym_quartile_range_WL3_N5'] \n",
            "Size of new training data set is:(149, 34)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.562e-03, tolerance: 3.375e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "# First convert the label to categorial values (0 and 1)\n",
        "encoder = LabelEncoder()\n",
        "label_training_cat = encoder.fit_transform(label_training) \n",
        "\n",
        "label_training_cat = label_training_cat.ravel()\n",
        "\n",
        "# Perform Lasso with cross-validation for 50 values of alpha on 10 segments\n",
        "lasso_cv = LassoCV(alphas=np.logspace(-4, 0, 100), cv=10)  \n",
        "lasso_cv.fit(data_training_normalized_df, label_training_cat)\n",
        "\n",
        "# Best alpha value\n",
        "best_alpha = lasso_cv.alpha_\n",
        "print(f\"Optimal Alpha: {best_alpha}\")\n",
        "\n",
        "# Fit LASSO again with optimal alpha\n",
        "lasso_opt = Lasso(alpha=best_alpha)\n",
        "lasso_opt.fit(data_training_normalized_df, label_training_cat)\n",
        "\n",
        "# Get final selected features\n",
        "selected_features = data_training_normalized_df.columns[lasso_opt.coef_ != 0]\n",
        "print(f\"Number of selected features: {len(selected_features)}\")\n",
        "print(f\"Final Selected Features: {list(selected_features)} \")\n",
        "\n",
        "#extract only the features of interest \n",
        "training_data_selected = data_training_normalized_df[selected_features]\n",
        "training_data_selected_df = pd.DataFrame(training_data_selected)\n",
        "\n",
        "print(f\"Size of new training data set is:{training_data_selected.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 1: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 1e-05, 'max_features': 'sqrt', 'max_depth': 8, 'bootstrap': True}\n",
            "Accuracy Validation set, fold 1: 0.80\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 2: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2, 'min_impurity_decrease': 5e-05, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
            "Accuracy Validation set, fold 2: 0.60\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 3: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 1e-05, 'max_features': 'sqrt', 'max_depth': 8, 'bootstrap': True}\n",
            "Accuracy Validation set, fold 3: 0.73\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 4: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 1e-05, 'max_features': 'sqrt', 'max_depth': 8, 'bootstrap': False}\n",
            "Accuracy Validation set, fold 4: 0.60\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 5: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 1e-05, 'max_features': 'sqrt', 'max_depth': 8, 'bootstrap': True}\n",
            "Accuracy Validation set, fold 5: 0.93\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 6: {'n_estimators': 150, 'min_samples_split': 3, 'min_samples_leaf': 2, 'min_impurity_decrease': 5e-05, 'max_features': 'sqrt', 'max_depth': 8, 'bootstrap': True}\n",
            "Accuracy Validation set, fold 6: 0.87\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 7: {'n_estimators': 150, 'min_samples_split': 3, 'min_samples_leaf': 2, 'min_impurity_decrease': 5e-05, 'max_features': 'sqrt', 'max_depth': 8, 'bootstrap': True}\n",
            "Accuracy Validation set, fold 7: 0.80\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 8: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 1e-05, 'max_features': 'sqrt', 'max_depth': 8, 'bootstrap': False}\n",
            "Accuracy Validation set, fold 8: 0.87\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 9: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2, 'min_impurity_decrease': 5e-05, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
            "Accuracy Validation set, fold 9: 0.67\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best Hyperparameters, fold 10: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 1e-05, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}\n",
            "Accuracy Validation set, fold 10: 0.71\n",
            "\n",
            "Best performing model found:\n",
            "Highest Validation Accuracy: 0.93\n",
            "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 1e-05, 'max_features': 'sqrt', 'max_depth': 8, 'bootstrap': True}\n"
          ]
        }
      ],
      "source": [
        "label_training_array = label_training_binary.values.flatten()\n",
        "#input_random_forest = data_training_normalized_df.values\n",
        "input_random_forest = training_data_selected_df\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#outer cross validatie\n",
        "outer_cv = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [150, 200],       #trees\n",
        "    'max_depth': [8, 10],              #maximum depth\n",
        "    'bootstrap': [True, False],           #bootstrap on or off\n",
        "    'min_samples_split': [3, 5],      #minimum samples required to split\n",
        "    'min_samples_leaf': [2, 3, 4],        #minimum samples wat je uiteindelijk in een leaf overhoudt \n",
        "    'max_features': ['sqrt'],     # controls the number of features selected, can also try log2 \n",
        "    'min_impurity_decrease': [0.00001, 0.00005, 0.0001]   # controls the minimum amount of impurity reduction required for a split to be created    \n",
        "}\n",
        "\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "n = 0\n",
        "best_model = None\n",
        "best_hyperparams = None\n",
        "highest_accuracy = 0\n",
        "rf_accuracies = []\n",
        "\n",
        "for train_idx, validate_idx in outer_cv.split(input_random_forest, label_training_array):\n",
        "    X_train, X_validate = input_random_forest.iloc[train_idx], input_random_forest.iloc[validate_idx]\n",
        "    y_train, y_validate = label_training_array[train_idx], label_training_array[validate_idx]\n",
        "    \n",
        "    n += 1\n",
        "\n",
        "    #de grid search naar de beste hyperparameters\n",
        "    #grid_search = model_selection.GridSearchCV(random_forest, param_grid, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "    grid_search = RandomizedSearchCV(random_forest, param_grid, cv=10, scoring='accuracy', n_iter=20, n_jobs=-1, random_state=42, verbose=1)\n",
        "\n",
        "    # Fit GridSearchCV to the data\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Print the best parameters\n",
        "    print(f\"Best Hyperparameters, fold {n}:\", grid_search.best_params_)\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    best_rf = grid_search.best_estimator_\n",
        "\n",
        "    accuracy = best_rf.score(X_validate, y_validate)\n",
        "    rf_accuracies.append(accuracy)\n",
        "\n",
        "    #checking of dit de hoogste accuracy tot nu toe is, ja dan replace, nee dan skip\n",
        "    if accuracy > highest_accuracy:\n",
        "        highest_accuracy = accuracy\n",
        "        best_model = best_rf\n",
        "        best_hyperparams = best_params\n",
        "\n",
        "    print(f\"Accuracy Validation set, fold {n}: {accuracy:.2f}\")\n",
        "\n",
        "print(\"\\nBest performing model found:\")\n",
        "print(f\"Highest Validation Accuracy: {highest_accuracy:.2f}\")\n",
        "print(f\"Best Hyperparameters: {best_hyperparams}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Get feature importances and compute standard deviation\n",
        "# importances = random_forest.feature_importances_\n",
        "# std = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)\n",
        "\n",
        "# # Sort feature importances\n",
        "# indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# # Print the top 5 most important features\n",
        "# print(\"Top 5 features by importance:\")\n",
        "# for i in range(5):\n",
        "#     print(f\"Feature {indices[i]}: {importances[indices[i]]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Suport Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 0.01, slack = 0.01 : 40.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 0.01, slack = 0.5 : 60.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 0.01, slack = 1 : 66.67%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 0.5, slack = 0.01 : 40.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 0.5, slack = 0.5 : 60.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 0.5, slack = 1 : 66.67%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 1, slack = 0.01 : 40.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 1, slack = 0.5 : 60.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 1, coef0 = 1, slack = 1 : 66.67%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 0.01, slack = 0.01 : 40.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 0.01, slack = 0.5 : 80.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 0.01, slack = 1 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 0.5, slack = 0.01 : 40.00%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 0.5, slack = 0.5 : 82.22%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 0.5, slack = 1 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 1, slack = 0.01 : 42.22%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 1, slack = 0.5 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 3, coef0 = 1, slack = 1 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 0.01, slack = 0.01 : 64.44%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 0.01, slack = 0.5 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 0.01, slack = 1 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 0.5, slack = 0.01 : 73.33%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 0.5, slack = 0.5 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 0.5, slack = 1 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 1, slack = 0.01 : 73.33%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 1, slack = 0.5 : 77.78%\n",
            "Accuracy for SVM with polynomial kernel                    degree = 5, coef0 = 1, slack = 1 : 77.78%\n"
          ]
        }
      ],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.svm import SVC\n",
        "label_training_array = label_training_binary.values.flatten()\n",
        "input_SVM = data_training_normalized_df.values\n",
        "\n",
        "# Construct classifiers\n",
        "degrees = [1, 3, 5]\n",
        "coef0s = [0.01, 0.5, 1]\n",
        "slacks = [0.01, 0.5, 1]\n",
        "\n",
        "for degree in degrees:\n",
        "    for coef0 in coef0s:\n",
        "        for slack in slacks:\n",
        "            SVM = SVC(kernel='poly', degree=degree, coef0=coef0, C=slack, gamma='scale')\n",
        "\n",
        "            X_train, X_validate, y_train, y_validate = model_selection.train_test_split(\n",
        "                input_SVM, label_training_array, test_size=0.3, random_state=42)\n",
        "            \n",
        "            # Fit the model on the training data\n",
        "            SVM.fit(X_train, y_train)\n",
        "\n",
        "            # Predict on the test set\n",
        "            y_pred = SVM.predict(X_validate)\n",
        "\n",
        "            # Compute accuracy\n",
        "            accuracy = metrics.accuracy_score(y_validate, y_pred)\n",
        "\n",
        "            print(f\"Accuracy for SVM with polynomial kernel \\\n",
        "                   degree = {degree}, coef0 = {coef0}, slack = {slack} : {accuracy * 100:.2f}%\")    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
            "Top 3 beste modellen:\n",
            "    param_degree  param_coef0  param_C  mean_test_score\n",
            "24             2         0.01      1.0         0.790152\n",
            "28             2         0.50      1.0         0.790152\n",
            "Accuracy Validation set: 0.83\n",
            "Best Hyperparameters: {'C': 0.01, 'coef0': 1, 'degree': 5}\n"
          ]
      ],
      "source": [
        "X_train_SVM, X_validate_SVM, y_train_SVM, y_validate_SVM = model_selection.train_test_split(input_SVM, label_training_array, test_size=0.2, random_state=42)\n",
        "\n",
        "SVM = SVC(kernel='poly')\n",
        "\n",
        "param_grid = {\n",
        "    'degree': [2, 3, 6, 5],                 #degree of polynomial\n",
        "    'coef0': [0.01, 0.5, 1],             #homogeniteit van de kernel\n",
        "    'C': [0.01, 0.5, 1],                 #slacks\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = model_selection.GridSearchCV(SVM, param_grid, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit GridSearchCV to the data\n",
        "grid_search.fit(X_train_SVM, y_train_SVM)\n",
        "\n",
        "# Resultaten ophalen en sorteren\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "results = results.sort_values(by=\"mean_test_score\", ascending=False)\n",
        "\n",
        "# Drie beste modellen tonen\n",
        "top_3_models = results[[\"param_degree\", \"param_coef0\", \"param_C\", \"mean_test_score\"]].head(3)\n",
        "print(\"Top 3 beste modellen:\")\n",
        "print(top_3_models)\n",
        "\n",
        "# Beste model selecteren en testen op validatieset\n",
        "best_SVM = grid_search.best_estimator_\n",
        "accuracy = best_SVM.score(X_validate_SVM, y_validate_SVM)\n",
        "print(f\"Accuracy Validation set: {accuracy:.2f}\")\n",
        "# Print the best parameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
