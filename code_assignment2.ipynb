{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e31ae3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0731fc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training + validation: 149 samples, Test: 37 samples.\n",
      "So total number of samples: 186\n",
      "The number of samples: 149\n",
      "The number of columns: 494\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 149 entries, Liver-030_0 to Liver-103_0\n",
      "Columns: 494 entries, label to PREDICT_original_phasef_phasesym_entropy_WL3_N5\n",
      "dtypes: float64(468), int64(25), object(1)\n",
      "memory usage: 576.2+ KB\n",
      "None\n",
      "categorical columns: 1\n",
      "numerical columns: 493\n",
      "samples with no variation: 0\n",
      "columns with no variation: 19\n",
      "Class Distribution: malignant label    76\n",
      "dtype: int64 and benign label    73\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Installation of the necessary packages\n",
    "\n",
    "#general packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "import seaborn\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#classifiers\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#other imports\n",
    "from worcliver.load_data import load_data\n",
    "\n",
    "### Loading the data\n",
    "data = load_data()\n",
    "\n",
    "### Division into training and test\n",
    "amount_in_training = round(len(data.index)*0.8)\n",
    "amount_in_test = round(len(data.index)*0.2)\n",
    "\n",
    "#split the data into training data and test data\n",
    "training_data, test_data = model_selection.train_test_split(data, test_size=(amount_in_test) / len(data), random_state=42)\n",
    "\n",
    "#checking the lengths\n",
    "print(f'Training + validation: {len(training_data)} samples, Test: {len(test_data)} samples.')\n",
    "print(f'So total number of samples: {len(training_data)+len(test_data)}')\n",
    "\n",
    "### Data inspection: only on the training set!\n",
    "\n",
    "print(f'The number of samples: {len(training_data.index)}')\n",
    "print(f'The number of columns: {len(training_data.columns)}')\n",
    "\n",
    "training_data_df = pd.DataFrame(training_data)\n",
    "print(training_data_df.info())\n",
    "cat_cols = training_data_df.select_dtypes(include=[\"object\"]).columns\n",
    "num_cols = training_data_df.select_dtypes(include=[\"number\"]).columns\n",
    "print(f\"categorical columns: {len(cat_cols)}\")\n",
    "print(f'numerical columns: {len(num_cols)}')\n",
    "\n",
    "no_variation_samples = 0\n",
    "for sample in training_data.index:\n",
    "    data_sample = training_data.drop(columns=['label'])\n",
    "    if data_sample.loc[sample].max() == data_sample.loc[sample].min():\n",
    "        no_variation_samples += 1\n",
    "no_variation_col = 0\n",
    "for feature in training_data.columns:\n",
    "    if training_data[feature].max() == training_data[feature].min():\n",
    "        no_variation_col += 1\n",
    "print(f'samples with no variation: {no_variation_samples}')\n",
    "print(f'columns with no variation: {no_variation_col}')\n",
    "\n",
    "label = training_data[['label']]\n",
    "malignant_count = (label == \"malignant\").sum()\n",
    "benign_count = (label == \"benign\").sum()\n",
    "\n",
    "print(f'Class Distribution: malignant {malignant_count} and benign {benign_count}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bdf40d",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "The function definitions of the functions used for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "900c1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some functions for the preprocessing of the data, decisions made based on training set results\n",
    "\n",
    "def determining_labels(training_data):\n",
    "    '''function definition'''\n",
    "    label_training = training_data[['label']]\n",
    "    training_data.drop(columns=['label'], inplace=True)\n",
    "\n",
    "    label_training_binary = label_training.copy()\n",
    "    label_training_binary['label'] = label_training_binary['label'].map({'malignant': 1, 'benign': 0})\n",
    "    return label_training_binary\n",
    "\n",
    "def handling_missing_data(training_data):\n",
    "    '''function definition'''\n",
    "    data_training = pd.DataFrame(training_data)\n",
    "\n",
    "    #if missing data is stored as NaN, replace with the mean\n",
    "    nan_check = data_training.isna()\n",
    "    nan_counts = nan_check.sum()\n",
    "    missing_data_features = nan_counts[nan_counts > 0].index.tolist()\n",
    "\n",
    "    for feature in missing_data_features:\n",
    "        mean_value = data_training[feature].mean()\n",
    "        data_training[feature].fillna(mean_value, inplace=True)\n",
    "    \n",
    "    #if missing data is stored as 0, don't handle this as missing data: values in Radiomics can also be determined as 0, so \n",
    "    #it cannot be stated that 0 is a missing value. \n",
    "\n",
    "    return data_training\n",
    "\n",
    "def shapiro_wilk_testing(data_training):\n",
    "    '''function definition'''\n",
    "    shapiro_results = {}\n",
    "    no_variation = 0\n",
    "    features_no_variation = []\n",
    "\n",
    "    for feature in data_training.columns:\n",
    "        if data_training[feature].max() == data_training[feature].min():\n",
    "            shapiro_results[feature] = None  #skipping the feature when there is no variation\n",
    "            no_variation += 1\n",
    "            features_no_variation.append(feature)\n",
    "        else:\n",
    "            #Shapiro-Wilk test to check for normality\n",
    "            stat, p_value = stats.shapiro(data_training[feature])\n",
    "\n",
    "            #if normally distributed, store 1, else store 0\n",
    "            if p_value > 0.05:\n",
    "                result = 1\n",
    "            else:\n",
    "                result = 0\n",
    "\n",
    "            shapiro_results[feature] = result\n",
    "\n",
    "    return features_no_variation, shapiro_results\n",
    "\n",
    "def normal_distributed_data(shapiro_results): #only relevant on training data, this determines the next steps!\n",
    "    '''function definition'''\n",
    "    if sum(1 for result in shapiro_results.values() if result == 0) > 0:\n",
    "        normal_distributed = False\n",
    "    return normal_distributed\n",
    "    \n",
    "def delete_no_varation(data_training, features_no_variation):\n",
    "    '''function definition'''\n",
    "    data_training_clean = data_training.drop(columns=features_no_variation)\n",
    "    return data_training_clean\n",
    "\n",
    "def standardize_data(data_training_clean, normal_distributed):\n",
    "    '''function definition'''\n",
    "    if not normal_distributed:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        data_training_standardized = scaler.fit_transform(data_training_clean)\n",
    "    else:\n",
    "        data_training_standardized = data_training_clean\n",
    "\n",
    "    data_training_standardized_df = pd.DataFrame(data_training_standardized, columns=data_training_clean.columns)\n",
    "    return data_training_standardized_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddd8cf",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "The function definitions of the functions used for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "69db9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Univariate selection\n",
    "\n",
    "def univariate_feature_selection(data_training_normalized_df):\n",
    "    '''function definition'''\n",
    "    corr_matrix = data_training_normalized_df.corr()\n",
    "\n",
    "    #step 1: calculate the correlation and associated p-value for every feature-pair\n",
    "    corr_matrix = pd.DataFrame(index=data_training_normalized_df.columns, columns=data_training_normalized_df.columns, dtype=float)\n",
    "    pval_matrix = pd.DataFrame(index=data_training_normalized_df.columns, columns=data_training_normalized_df.columns, dtype=float)\n",
    "\n",
    "    for col1 in data_training_normalized_df.columns:\n",
    "        for col2 in data_training_normalized_df.columns:\n",
    "            if col1 == col2:\n",
    "                corr_matrix.loc[col1, col2] = 1.0\n",
    "                pval_matrix.loc[col1, col2] = 0.0\n",
    "            else:\n",
    "                r, p = stats.pearsonr(data_training_normalized_df[col1], data_training_normalized_df[col2])\n",
    "                corr_matrix.loc[col1, col2] = r\n",
    "                pval_matrix.loc[col1, col2] = p\n",
    "\n",
    "\n",
    "    #step 2: loop through all the feature pairs and determine which ones have a high correlation and low p-value\n",
    "    threshold = 0.9\n",
    "    p_threshold = 0.05\n",
    "\n",
    "    to_drop = set()\n",
    "\n",
    "    for i, col1 in enumerate(data_training_normalized_df.columns):\n",
    "        for j, col2 in enumerate(data_training_normalized_df.columns):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            r = corr_matrix.loc[col1, col2]\n",
    "            p = pval_matrix.loc[col1, col2]\n",
    "\n",
    "            if abs(r) > threshold and p < p_threshold:\n",
    "                if col1 not in to_drop and col2 not in to_drop:\n",
    "                    col_to_drop = col2\n",
    "                    to_drop.add(col_to_drop)\n",
    "\n",
    "    print(\"Dropped features due to high correlation:\")\n",
    "    print(to_drop)\n",
    "\n",
    "    #step 3: drop one of the features in a feature pair with high correlation and low p-value\n",
    "    data_training_reduced = data_training_normalized_df.drop(columns=to_drop)\n",
    "\n",
    "    print(f\"Size of new training data set is:{data_training_reduced.shape}; Old was: {data_training_normalized_df.shape}\")\n",
    "    return data_training_reduced\n",
    "\n",
    "\n",
    "def lasso_feature_selection(data_training_reduced, label_training_binary):\n",
    "    '''function definition'''\n",
    "    label_training_array = label_training_binary.values.flatten()\n",
    "\n",
    "    #step 1: perform Lasso with cross-validation for 50 values of alpha on 10 segments over 10.000 iterations\n",
    "    lasso_cv = LassoCV(alphas=np.logspace(-4, 0, 100), cv=10, max_iter=10000)  \n",
    "    lasso_cv.fit(data_training_reduced, label_training_array)\n",
    "\n",
    "    #step 2: find the best alpha value\n",
    "    best_alpha = lasso_cv.alpha_\n",
    "    print(f\"Optimal Alpha: {best_alpha}\")\n",
    "\n",
    "    #step 3: fit LASSO again with optimal alpha\n",
    "    lasso_opt = Lasso(alpha=best_alpha)\n",
    "    lasso_opt.fit(data_training_reduced, label_training_array)\n",
    "\n",
    "    #step 4: get the features of interest, and only extract those\n",
    "    selected_features = data_training_reduced.columns[lasso_opt.coef_ != 0]\n",
    "    print(f\"Number of selected features: {len(selected_features)}\")\n",
    "    print(f\"Final Selected Features: {list(selected_features)} \")\n",
    "\n",
    "    training_data_selected = data_training_reduced[selected_features]\n",
    "    training_data_selected_df = pd.DataFrame(training_data_selected)\n",
    "\n",
    "    print(f\"Size of new training data set is:{training_data_selected.shape}\")\n",
    "    return training_data_selected_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f3d81",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "### K-Nearest Neighbours\n",
    "Function definition used for the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "330b2975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classifier(training_data_selected_df, label_training_binary):\n",
    "\n",
    "\n",
    "    label_training_array = label_training_binary.values.flatten()\n",
    "    input_knn = training_data_selected_df\n",
    "\n",
    "    x_train_KNN = input_knn\n",
    "    y_train_KNN = label_training_array\n",
    "\n",
    "    x_train_KNN = np.ascontiguousarray(x_train_KNN.values, dtype=np.float64)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_neighbors': list(range(1, 31)),\n",
    "    }   \n",
    "\n",
    "    # Initialize the classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    # GridSearchCV to find the best k\n",
    "    grid_search = model_selection.GridSearchCV(knn, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1, return_train_score=True, error_score='raise')\n",
    "\n",
    "    # Fit model\n",
    "    grid_search.fit(x_train_KNN, y_train_KNN)\n",
    "\n",
    "    # Convert cv_results_ to a DataFrame for easier manipulation\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "    # Vind alle individuele fold score kolommen\n",
    "    fold_columns = [col for col in results_df.columns if col.startswith(\"split\") and col.endswith(\"_test_score\")]\n",
    "\n",
    "    # Aantal folds\n",
    "    n_folds = len(fold_columns)\n",
    "\n",
    "    # Functie om CI te berekenen per rij\n",
    "    def compute_confidence_interval(row):\n",
    "        scores = row[fold_columns].values\n",
    "        #############################################vanaf hier gaat het mis, scores is leeg\n",
    "        mean = np.mean(scores)\n",
    "        std = np.std(scores, ddof=1)  # sample std dev\n",
    "        ci_halfwidth = stats.norm.ppf(0.975) * std / np.sqrt(n_folds)\n",
    "        return pd.Series({\n",
    "            'mean_score': mean,\n",
    "            'std_score': std,\n",
    "            'ci_lower': mean - ci_halfwidth,\n",
    "            'ci_upper': mean + ci_halfwidth\n",
    "        })\n",
    "\n",
    "    # Pas toe op elke rij (elke modelconfiguratie)\n",
    "    ci_df = results_df.apply(compute_confidence_interval, axis=1)\n",
    "\n",
    "    # Build a DataFrame with all the relevant info\n",
    "    final_df = pd.concat([\n",
    "        results_df[['params', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']],\n",
    "        ci_df\n",
    "    ], axis=1)\n",
    "\n",
    "    #final_df = pd.concat([results_df['params'], ci_df], axis=1)\n",
    "\n",
    "    # Print de top 5 met hoogste mean_score\n",
    "    top_models = final_df.sort_values(by='mean_score', ascending=False).head(5)\n",
    "    print(top_models)\n",
    "\n",
    "    #retraining the model with the top parameters\n",
    "    top_params_KNN = top_models.iloc[0]['params']\n",
    "    final_KNN_model = KNeighborsClassifier(**top_params_KNN)\n",
    "    final_KNN_model.fit(x_train_KNN, y_train_KNN)\n",
    "\n",
    "    return final_KNN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ede8bd",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "Function definition used for the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0bcb5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(training_data_selected_df, label_training_binary):\n",
    "    label_training_array = label_training_binary.values.flatten()\n",
    "    input_random_forest = training_data_selected_df\n",
    "    \n",
    "    X_train_RF = input_random_forest\n",
    "    y_train_RF = label_training_array\n",
    "\n",
    "    X_train_RF = np.ascontiguousarray(X_train_RF.values, dtype=np.float64)\n",
    "\n",
    "    param_grid_RF = {\n",
    "        'n_estimators': [110, 115, 120],                     #trees\n",
    "        'max_depth': [5, 8, 13],                         #maximum depth\n",
    "        'bootstrap': [True],                     #bootstrap on or off >> moet dus True of False zijn, maar aangezien er altijd True kwam dat nu even gelaten voor snelheid runnen\n",
    "        'min_samples_split': [2, 3, 4, 5],                    #minimum samples required to split\n",
    "        'min_samples_leaf': [1, 2, 3],                  #minimum samples wat je uiteindelijk in een leaf overhoudt \n",
    "        'max_features': ['sqrt', 'log2'],                       #controls the number of features selected, can also try log2 \n",
    "        'min_impurity_decrease': [0.00001, 0.000005, 0.00002]   #controls the minimum amount of impurity reduction required for a split to be created    \n",
    "    }\n",
    "\n",
    "    random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    #de grid search naar de beste hyperparameters\n",
    "    grid_search_RF = model_selection.GridSearchCV(random_forest, param_grid_RF, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    #grid_search = RandomizedSearchCV(random_forest, param_grid, cv=10, scoring='accuracy', n_iter=20, n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "    # Fit GridSearchCV to the data\n",
    "    grid_search_RF.fit(X_train_RF, y_train_RF)\n",
    "\n",
    "    #find the accuracies per fold\n",
    "    results_df_RF = pd.DataFrame(grid_search_RF.cv_results_)\n",
    "\n",
    "    # Vind alle individuele fold score kolommen\n",
    "    fold_columns_RF = [col for col in results_df_RF.columns if col.startswith(\"split\") and col.endswith(\"_test_score\")]\n",
    "\n",
    "    # Aantal folds\n",
    "    n_folds_RF = len(fold_columns_RF)\n",
    "\n",
    "    # Functie om CI te berekenen per rij\n",
    "    def compute_confidence_interval_RF(row):\n",
    "        scores = row[fold_columns_RF].values\n",
    "        mean = np.mean(scores)\n",
    "        std = np.std(scores, ddof=1)  # sample std dev\n",
    "        ci_halfwidth = stats.norm.ppf(0.975) * std / np.sqrt(n_folds_RF)\n",
    "        return pd.Series({\n",
    "            'mean_score': mean,\n",
    "            'std_score': std,\n",
    "            'ci_lower': mean - ci_halfwidth,\n",
    "            'ci_upper': mean + ci_halfwidth\n",
    "        })\n",
    "\n",
    "    # Pas toe op elke rij (elke modelconfiguratie)\n",
    "    ci_RF = results_df_RF.apply(compute_confidence_interval_RF, axis=1)\n",
    "\n",
    "    # Combineer met de parameterinstellingen\n",
    "    final_RF = pd.concat([results_df_RF['params'], ci_RF], axis=1)\n",
    "\n",
    "    # Print de top 5 met hoogste mean_score\n",
    "    top_models_RF = final_RF.sort_values(by='mean_score', ascending=False).head(5)\n",
    "\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(top_models_RF)\n",
    "\n",
    "    #retraining the model with the top parameters\n",
    "    top_params_RF = top_models_RF.iloc[0]['params']\n",
    "    final_RF_model = RandomForestClassifier(**top_params_RF, random_state=42)\n",
    "    final_RF_model.fit(X_train_RF, y_train_RF)\n",
    "\n",
    "    return final_RF_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1bd854",
   "metadata": {},
   "source": [
    "### Support vector machine\n",
    "Function definition used for the support vector machine classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "15960596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_classifier(training_data_selected_df, label_training_binary):\n",
    "    label_training_array = label_training_binary.values.flatten()\n",
    "    input_SVM = training_data_selected_df\n",
    "\n",
    "    X_train_SVM = input_SVM\n",
    "    y_train_SVM = label_training_array\n",
    "\n",
    "    X_train_SVM = np.ascontiguousarray(X_train_SVM.values, dtype=np.float64)\n",
    "\n",
    "    param_grid_SVM = {\n",
    "        'kernel': ['linear', 'poly', 'rbf'],        # kernel-types\n",
    "        'C': [0.01, 0.1, 1, 2, 3, 5, 10, 100],      # Expand the range of C values\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.05, 0.1, 0.2, 0.5], # Add more gamma values\n",
    "        'degree': [1, 3, 5, 10, 12, 15],            # Add more degree values for polynomial kernel\n",
    "        'coef0': [0.0, 0.01, 0.5, 1, 2]             # Extend coef0 range\n",
    "    }\n",
    "\n",
    "    SVM_model = SVC()\n",
    "\n",
    "    #de grid search naar de beste hyperparameters\n",
    "    grid_search_SVM = model_selection.GridSearchCV(SVM_model, param_grid_SVM, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    #grid_search = RandomizedSearchCV(random_forest, param_grid, cv=10, scoring='accuracy', n_iter=20, n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "    # Fit GridSearchCV to the data\n",
    "    grid_search_SVM.fit(X_train_SVM, y_train_SVM)\n",
    "\n",
    "    #find the accuracies per fold\n",
    "    results_df_SVM = pd.DataFrame(grid_search_SVM.cv_results_)\n",
    "\n",
    "    # Vind alle individuele fold score kolommen\n",
    "    fold_columns_SVM = [col for col in results_df_SVM.columns if col.startswith(\"split\") and col.endswith(\"_test_score\")]\n",
    "\n",
    "    # Aantal folds\n",
    "    n_folds_SVM = len(fold_columns_SVM)\n",
    "\n",
    "    # Functie om CI te berekenen per rij\n",
    "    def compute_confidence_interval_SVM(row):\n",
    "        scores = row[fold_columns_SVM].values\n",
    "        mean = np.mean(scores)\n",
    "        std = np.std(scores, ddof=1)  # sample std dev\n",
    "        ci_halfwidth = stats.norm.ppf(0.975) * std / np.sqrt(n_folds_SVM)\n",
    "        return pd.Series({\n",
    "            'mean_score': mean,\n",
    "            'std_score': std,\n",
    "            'ci_lower': mean - ci_halfwidth,\n",
    "            'ci_upper': mean + ci_halfwidth\n",
    "        })\n",
    "\n",
    "    # Pas toe op elke rij (elke modelconfiguratie)\n",
    "    ci_SVM = results_df_SVM.apply(compute_confidence_interval_SVM, axis=1)\n",
    "\n",
    "    # Combineer met de parameterinstellingen\n",
    "    final_SVM = pd.concat([results_df_SVM['params'], ci_SVM], axis=1)\n",
    "\n",
    "    # Print de top 5 met hoogste mean_score\n",
    "    top_models_SVM = final_SVM.sort_values(by='mean_score', ascending=False).head(5)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(top_models_SVM)\n",
    "\n",
    "    #retraining the model with the top parameters\n",
    "    top_params_SVM = top_models_SVM.iloc[0]['params']\n",
    "    final_SVM_model = SVC(**top_params_SVM)\n",
    "    final_SVM_model.fit(X_train_SVM, y_train_SVM)\n",
    "\n",
    "    return final_SVM_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a778952c",
   "metadata": {},
   "source": [
    "### Creating the machine learning models and testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the data\n",
    "data = load_data()\n",
    "\n",
    "### Division into training and test\n",
    "amount_in_training = round(len(data.index)*0.8)\n",
    "amount_in_test = round(len(data.index)*0.2)\n",
    "\n",
    "results = []\n",
    "roc_data = {\n",
    "    \"KNN\": [],\n",
    "    \"RF\": [],\n",
    "    \"SVM\": [],\n",
    "    \"KNN + LASSO\": [],\n",
    "    \"RF + LASSO\": [],\n",
    "    \"SVM + LASSO\": []\n",
    "}\n",
    "\n",
    "#split the data into training data and test data\n",
    "for i in range(5):\n",
    "    training_data, test_data = model_selection.train_test_split(\n",
    "        data, test_size=(amount_in_test) / len(data), random_state=np.random.randint(10000)\n",
    "    )\n",
    "\n",
    "    ### Preprocessing the training data\n",
    "    label_training_binary = determining_labels(training_data)\n",
    "    data_training = handling_missing_data(training_data)\n",
    "    features_no_variation, shapiro_results = shapiro_wilk_testing(data_training)\n",
    "    normal_distributed = normal_distributed_data(shapiro_results)\n",
    "    data_training_clean = delete_no_varation(data_training, features_no_variation)\n",
    "    data_training_normalized_df = standardize_data(data_training_clean, normal_distributed)\n",
    "\n",
    "    ### Preprocessing the test data\n",
    "    label_test_binary = determining_labels(test_data)\n",
    "    data_test = handling_missing_data(test_data)\n",
    "    data_test_clean = delete_no_varation(data_test, features_no_variation)\n",
    "    data_test_normalized_df = standardize_data(data_test_clean, normal_distributed)\n",
    "\n",
    "    ### Preprocessing all the data together (needed for learning curves)\n",
    "    label_binary = determining_labels(data)\n",
    "    data = handling_missing_data(data)\n",
    "    data_clean = delete_no_varation(data, features_no_variation)\n",
    "    data_normalized_df = standardize_data(data_clean, normal_distributed)\n",
    "\n",
    "    ### Feature selection\n",
    "    data_training_univariate = univariate_feature_selection(data_training_normalized_df)\n",
    "    training_data_selected_df = lasso_feature_selection(data_training_univariate, label_training_binary)\n",
    "\n",
    "    ### Training the classifiers\n",
    "    final_KNN_model_LASSO = KNN_classifier(training_data_selected_df, label_training_binary)\n",
    "    final_RF_model_LASSO = random_forest_classifier(training_data_selected_df, label_training_binary)\n",
    "    final_SVM_model_LASSO = SVM_classifier(training_data_selected_df, label_training_binary)\n",
    "\n",
    "    final_KNN_model = KNN_classifier(data_training_univariate, label_training_binary)\n",
    "    final_RF_model = random_forest_classifier(data_training_univariate, label_training_binary)\n",
    "    final_SVM_model = SVM_classifier(data_training_univariate, label_training_binary)\n",
    "\n",
    "    #accuracy of the prediction of the test set\n",
    "    y_test = label_test_binary.values.flatten()\n",
    "    X_test_LASSO = data_test_normalized_df.reset_index(drop=True)[training_data_selected_df.columns]\n",
    "    X_test_LASSO = np.ascontiguousarray(X_test_LASSO.values, dtype=np.float64)\n",
    "    X_test = data_test_normalized_df.reset_index(drop=True)[data_training_univariate.columns]\n",
    "    X_test = np.ascontiguousarray(X_test.values, dtype=np.float64)\n",
    "\n",
    "    result_row = []\n",
    "\n",
    "    for model, X in [(final_KNN_model, X_test), (final_RF_model, X_test), (final_SVM_model, X_test),\n",
    "                     (final_KNN_model_LASSO, X_test_LASSO), (final_RF_model_LASSO, X_test_LASSO), (final_SVM_model_LASSO, X_test_LASSO)]:\n",
    "        y_pred = model.predict(X)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        result_row.extend([acc, auc])\n",
    "\n",
    "    results.append(result_row)\n",
    "\n",
    "    models_info = {\n",
    "        \"KNN\": (final_KNN_model, X_test),\n",
    "        \"RF\": (final_RF_model, X_test),\n",
    "        \"SVM\": (final_SVM_model, X_test),\n",
    "        \"KNN + LASSO\": (final_KNN_model_LASSO, X_test_LASSO),\n",
    "        \"RF + LASSO\": (final_RF_model_LASSO, X_test_LASSO),\n",
    "        \"SVM + LASSO\": (final_SVM_model_LASSO, X_test_LASSO)\n",
    "    }\n",
    "\n",
    "    for label, (model, X_input) in models_info.items():\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_score = model.predict_proba(X_input)[:, 1]\n",
    "        elif hasattr(model, \"decision_function\"):\n",
    "            y_score = model.decision_function(X_input)\n",
    "        else:\n",
    "            y_score = model.predict(X_input)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "        roc_data[label].append((fpr, tpr))\n",
    "\n",
    "# Convert to numpy array for easier handling\n",
    "results_array = np.array(results)\n",
    "\n",
    "# Optional: show as DataFrame for readability\n",
    "import pandas as pd\n",
    "columns = [\n",
    "    \"KNN_Acc\", \"KNN_AUC\", \"RF_Acc\", \"RF_AUC\", \"SVM_Acc\", \"SVM_AUC\",\n",
    "    \"KNN_LASSO_Acc\", \"KNN_LASSO_AUC\", \"RF_LASSO_Acc\", \"RF_LASSO_AUC\", \"SVM_LASSO_Acc\", \"SVM_LASSO_AUC\"\n",
    "]\n",
    "results_df = pd.DataFrame(results_array, columns=columns)\n",
    "print(results_df)\n",
    "\n",
    "# === Plotting ROC curves ===\n",
    "for label, curves in roc_data.items():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, (fpr, tpr) in enumerate(curves):\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'Split {i+1} (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.title(f'ROC Curve - {label}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # y_pred_KNN = final_KNN_model.predict(X_test)\n",
    "    # test_accuracy_KNN = accuracy_score(y_test, y_pred_KNN)\n",
    "    # test_auc_KNN = roc_auc_score(y_test, y_pred_KNN)\n",
    "    # print(f\"Test Accuracy of KNN without LASSO: {test_accuracy_KNN:.4f}\")\n",
    "    # print(f\"Test AUC of KNN without LASSO: {test_auc_KNN:.4f}\")\n",
    "\n",
    "    # y_pred_KNN_LASSO = final_KNN_model_LASSO.predict(X_test_LASSO)\n",
    "    # test_accuracy_KNN_LASSO = accuracy_score(y_test, y_pred_KNN_LASSO)\n",
    "    # test_auc_KNN_LASSO = roc_auc_score(y_test, y_pred_KNN_LASSO)\n",
    "    # print(f\"Test Accuracy of KNN with LASSO: {test_accuracy_KNN_LASSO:.4f}\")\n",
    "    # print(f\"Test AUC of KNN with LASSO: {test_auc_KNN_LASSO:.4f}\")\n",
    "\n",
    "    # y_pred_RF = final_RF_model.predict(X_test)\n",
    "    # test_accuracy_RF = accuracy_score(y_test, y_pred_RF)\n",
    "    # test_auc_RF = roc_auc_score(y_test, y_pred_RF)\n",
    "    # print(f\"Test Accuracy of RF without LASSO: {test_accuracy_RF:.4f}\")\n",
    "    # print(f\"Test AUC of RF without LASSO: {test_auc_RF:.4f}\")\n",
    "\n",
    "    # y_pred_RF_LASSO = final_RF_model_LASSO.predict(X_test_LASSO)\n",
    "    # test_accuracy_RF_LASSO = accuracy_score(y_test, y_pred_RF_LASSO)\n",
    "    # test_auc_RF_LASSO = roc_auc_score(y_test, y_pred_RF_LASSO)\n",
    "    # print(f\"Test Accuracy of RF with LASSO: {test_accuracy_RF_LASSO:.4f}\")\n",
    "    # print(f\"Test AUC of RF with LASSO: {test_auc_RF_LASSO:.4f}\")\n",
    "\n",
    "    # y_pred_SVM = final_SVM_model.predict(X_test)\n",
    "    # test_accuracy_SVM = accuracy_score(y_test, y_pred_SVM)\n",
    "    # test_auc_SVM = roc_auc_score(y_test, y_pred_SVM)\n",
    "    # print(f\"Test Accuracy of SVM without LASSO: {test_accuracy_SVM:.4f}\")\n",
    "    # print(f\"Test AUC of SVM without LASSO: {test_auc_SVM:.4f}\")\n",
    "\n",
    "    # y_pred_SVM_LASSO = final_SVM_model_LASSO.predict(X_test_LASSO)\n",
    "    # test_accuracy_SVM_LASSO = accuracy_score(y_test, y_pred_SVM_LASSO)\n",
    "    # test_auc_SVM_LASSO = roc_auc_score(y_test, y_pred_SVM_LASSO)\n",
    "    # print(f\"Test Accuracy of SVM with LASSO: {test_accuracy_SVM_LASSO:.4f}\")\n",
    "    # print(f\"Test AUC of SVM with LASSO: {test_auc_SVM_LASSO:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
